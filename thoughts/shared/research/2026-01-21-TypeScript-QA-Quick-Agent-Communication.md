# Research Report: TypeScript-QA-Quick Agent-to-Agent Communication Optimization

## Metadata
- Date: 2026-01-21
- Researcher: Researcher Agent
- Topic: "TypeScript-QA-Quick Agent-to-Agent Communication Optimization"
- Status: complete
- Coverage:
  - agent/typescript-qa-quick.md (agent definition and output template)
  - AGENTS.md (thinking/answer pattern guidelines, QA workflow)
  - Background research from 2026-01-20-OpenCode-QA-Thorough-Agent-Communication.md
  - Background research from 2026-01-21-Python-QA-Quick-Agent-Communication.md

## Executive Summary

- The typescript-qa-quick agent produces rapid TypeScript QA task lists but lacks thinking/answer separation despite being an all-mode user-facing agent
- **Gap 1 (Critical)**: No separation of analysis process (<thinking>) from final findings (<answer>), preventing debugging and token optimization for downstream consumers
- **Gap 2 (Medium)**: No structured message envelope (YAML frontmatter with correlation IDs) for multi-step workflow tracking
- **Gap 3 (Documentation)**: Agent not listed in AGENTS.md thinking/answer pattern section despite meeting criteria (all-mode agent that produces user-facing output)
- Verbosity analysis: Output format is naturally concise (task list, not detailed report), no fixed-verbosity problem
- Highest-impact recommendation: Add <thinking>/<answer> separation to enable user debugging (~10-13% overhead)
- Secondary recommendation: Add YAML frontmatter message envelope for workflow correlation (~3% overhead)
- **Pattern Consistency**: typescript-qa-quick is parallel to python-qa-quick, both should use same communication pattern

## Coverage Map

**Files Inspected**:
- `agent/typescript-qa-quick.md` (agent definition, lines 1-318, verified complete at 318 lines)
- `AGENTS.md` (lines 1-100 for thinking/answer pattern, spot-checked QA workflow documentation)

**Background Research** (not re-verified, relied on prior analysis):
- `thoughts/shared/research/2026-01-20-OpenCode-QA-Thorough-Agent-Communication.md` (QA agent communication patterns)
- `thoughts/shared/research/2026-01-21-Python-QA-Quick-Agent-Communication.md` (python-qa-quick analysis, parallel agent)
- `thoughts/shared/research/2026-01-18-Codebase-Analyzer-Agent-Communication.md` (industry best practices from 7 authoritative sources)

**Scope**:
- Complete analysis of typescript-qa-quick output structure
- Evidence-based comparison against AGENTS.md guidelines
- Gap identification using python-qa-quick research as baseline (parallel agent)
- Comparison to python-qa-quick for consistency
- No implementation changes made (research only)

## Critical Findings (Verified, Planner Attention Required)

### Finding 1: No Thinking/Answer Separation Despite All-Mode User-Facing Role

**Observation**: The typescript-qa-quick agent produces QA task lists directly for users but does not separate analysis reasoning (<thinking>) from final findings (<answer>), violating the pattern documented in AGENTS.md for agents that communicate directly with users.

**Direct consequence**: Users cannot inspect the agent's reasoning process (which tools were executed, what versions were detected, how issues were prioritized), and downstream QA-Planner agents cannot strip reasoning tokens when parsing tasks.

**Evidence**: `agent/typescript-qa-quick.md:136-162` (output template)
**Excerpt**:
```markdown
## Output Format

Use this exact Markdown structure:

```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD

### üî¥ Critical Issues (Fix Immediately)
- [ ] [Issue description] - `[File:Line]` - [Tool]
```

**Evidence**: `AGENTS.md:9-27` (thinking/answer pattern guideline)
**Excerpt**:
```markdown
### Thinking/Answer Separation for User-Facing Outputs

Primary agents that communicate directly with users should separate operational reasoning from actionable results using a structured three-part format:

#### Pattern Structure

```markdown
<thinking>
[Document decision-making process, file reads, parsing, analysis, verification reasoning]
</thinking>

<answer>
---
[YAML frontmatter with message_id, correlation_id, status fields]
---

[User-facing status and actionable information]
</answer>
```
```

**Gap Identified**: typescript-qa-quick is NOT listed in AGENTS.md:29-39 despite being an all-mode agent that produces user-facing QA output.

**Comparison to python-qa-quick**: python-qa-quick IS documented in AGENTS.md:37 with "Documents automated tool execution reasoning (commands, versions, raw outputs, synthesis decisions)". typescript-qa-quick should use the same pattern for consistency.

**Token Impact**: Estimated +150-200 tokens for <thinking> section (+10-13% overhead for typical quick QA run).

### Finding 2: Output Template Shows No Reasoning Trail

**Observation**: The typescript-qa-quick output template at `agent/typescript-qa-quick.md:136-162` produces clean task lists with file:line references but does not document HOW the agent arrived at its conclusions.

**Direct consequence**: If a user questions why an issue was categorized as "Critical" vs "High Priority", or wonders what exact tsc/eslint/knip commands were run, there is no visible audit trail in the output.

**Evidence**: `agent/typescript-qa-quick.md:136-162` (output template)
**Excerpt**:
```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD

### üî¥ Critical Issues (Fix Immediately)
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü† High Priority
- [ ] [Issue description] - `[File:Line]` - [Tool]
```

**Missing Information** (should be in <thinking>):
- What exact commands were executed? (e.g., `npx tsc --noEmit`, `npx eslint . --ext .ts,.tsx`)
- What tool versions were detected?
- What was the raw output from each tool?
- How many total issues were found before grouping?
- Why was a specific issue categorized as Critical vs High vs Medium?
- Which optional tools were detected and run (eslint-plugin-security, eslint-plugin-jsdoc)?

**Comparison to python-qa-quick**: python-qa-quick thinking section includes "commands, versions, raw outputs, synthesis decisions" (AGENTS.md:37). typescript-qa-quick should include the same.

**Token Impact**: Users must trust agent's judgment without visibility into decision process.

### Finding 3: No Message Envelope for Workflow Correlation

**Observation**: The typescript-qa-quick agent produces inline output but does not include structured message metadata (correlation IDs, timestamps, message types) in YAML frontmatter.

**Direct consequence**: Cannot correlate quick QA runs with downstream actions or other workflow steps, making multi-step debugging difficult.

**Evidence**: `agent/typescript-qa-quick.md:136-162` (template structure)
**Excerpt**:
```markdown
## Output Format

Use this exact Markdown structure:

```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD
```
```

**Gap Identified**: Scan Summary uses Markdown section for metadata instead of YAML frontmatter, inconsistent with other primary agents.

**Evidence**: `AGENTS.md:46` (documented benefit)
**Excerpt**:
```markdown
- **Workflow correlation via YAML frontmatter**: `message_id` and `correlation_id` enable tracing outputs across agents
```

**Comparison to python-qa-quick**: python-qa-quick should use YAML frontmatter (per research 2026-01-21). typescript-qa-quick should match for consistency.

**Token Impact**: +40-50 tokens (+3%) for message envelope, significant debugging value.

### Finding 4: Output Naturally Concise (Task List Format)

**Observation**: The typescript-qa-quick output template produces task lists, not detailed reports. The format is inherently concise with checkboxes and file:line references.

**Direct consequence**: No fixed-verbosity problem like codebase-analyzer. The output scales naturally with findings (0 critical issues = empty Critical section, 50 critical issues = 50 checkboxes).

**Evidence**: `agent/typescript-qa-quick.md:136-162` (output template)
**Excerpt**:
```markdown
### üî¥ Critical Issues (Fix Immediately)
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü† High Priority
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü° Medium Priority
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü¢ Low Priority / Style
- [ ] [Issue description] - `[File:Line]` - [Tool]
```

**Evidence**: `agent/typescript-qa-quick.md:174-175` (grouping instruction)
**Excerpt**:
```markdown
   - Group similar issues to avoid overwhelming output (max 20 items per category)
   - If more than 20 issues in a category, summarize: "X additional similar issues in [file]"
```

**Analysis**: Template has conditional content (empty sections if no issues), plus grouping to prevent overwhelming output. This is optimal design for quick QA feedback.

**Token Impact**: No verbosity optimization needed; current design is efficient.

### Finding 5: Parallel Agent Consistency Gap

**Observation**: typescript-qa-quick is parallel to python-qa-quick (both are "quick QA" agents for different languages). python-qa-quick is documented in AGENTS.md:37 as using thinking/answer pattern, but typescript-qa-quick is not.

**Direct consequence**: Inconsistent user experience across parallel agents. Users working on polyglot projects will see different output formats from quick QA agents.

**Evidence**: `AGENTS.md:37`
**Excerpt**:
```markdown
- **python-qa-quick** (`agent/python-qa-quick.md`): Documents automated tool execution reasoning (commands, versions, raw outputs, synthesis decisions)
```

**Evidence**: `agent/typescript-qa-quick.md:1-20` (agent metadata)
**Excerpt**:
```markdown
---
description: "Quick TypeScript QA check using tsc, eslint, and knip. Outputs actionable tasks immediately without writing plan files."
mode: all
temperature: 0.1
```

**Gap Identified**: Both agents should use the same thinking/answer pattern with the same thinking section content (commands, versions, raw outputs, synthesis decisions).

**Token Impact**: Consistency improvement, no additional overhead beyond recommendation 1.

## Detailed Technical Analysis (Verified)

### Current typescript-qa-quick Output Structure

**Template Location**: `agent/typescript-qa-quick.md:136-162`

**Structure** (6 sections, all conditional):

**Fixed Sections** (always present):
1. **Scan Summary**: Target path, tools used (‚úì/‚ùå status), date

**Conditional Sections** (scale with findings):
2. **üî¥ Critical Issues**: Security vulnerabilities from eslint-plugin-security
3. **üü† High Priority**: Type errors from tsc that block compilation
4. **üü° Medium Priority**: Quality issues from eslint + unused code from knip
5. **üü¢ Low Priority / Style**: Style issues from eslint + React patterns
6. **‚úÖ Next Steps**: Concrete actions to take

**Evidence**: `agent/typescript-qa-quick.md:136-162`
**Excerpt**:
```markdown
## Output Format

Use this exact Markdown structure:

```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD

### üî¥ Critical Issues (Fix Immediately)
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü† High Priority
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü° Medium Priority
- [ ] [Issue description] - `[File:Line]` - [Tool]

### üü¢ Low Priority / Style
- [ ] [Issue description] - `[File:Line]` - [Tool]

### ‚úÖ Next Steps
[Concrete actions to take]
```
```

**Strengths**:
- Task list format is concise and actionable
- Emoji-based visual hierarchy (üî¥üü†üü°üü¢) for quick scanning
- File:line references for every issue
- Clear tool attribution (tsc, eslint, knip, eslint-plugin-security)
- Grouping mechanism to prevent overwhelming output (max 20 per category)
- Scales naturally with findings (empty sections if no issues)

**Weaknesses**:
- No <thinking>/<answer> separation (reasoning mixed or absent)
- No YAML frontmatter message envelope
- Not documented in AGENTS.md thinking/answer pattern list
- Inconsistent with parallel python-qa-quick agent

### Tool Execution Analysis

**Tool Set**: `agent/typescript-qa-quick.md:97-114`

**Core Tools** (always run if available):
1. `npx tsc --noEmit` (type checking)
2. `npx eslint . --ext .ts,.tsx` (linting)
3. `npx knip --reporter compact` (dead code detection)

**Optional Tools** (run if detected in config):
4. `npx eslint . --ext .ts,.tsx --plugin security` (security vulnerabilities)
5. `npx eslint . --ext .ts,.tsx --plugin jsdoc` (documentation issues)

**Evidence**: `agent/typescript-qa-quick.md:97-114`
**Excerpt**:
```markdown
### 2. Execute Analysis Tools (in parallel)

Run the following commands using the bash tool:

```bash
npx tsc --noEmit
npx eslint . --ext .ts,.tsx
npx knip --reporter compact
```

Execute these three commands in parallel for speed.

**Optional tools** (if plugins detected in package.json or eslint config):
```bash
npx eslint . --ext .ts,.tsx --plugin security
npx eslint . --ext .ts,.tsx --plugin jsdoc
```
```

**Analysis**: Agent runs 3-5 tools in parallel, then synthesizes results. This execution strategy should be documented in <thinking> section.

### Prioritization Logic

**Priority Hierarchy**: `agent/typescript-qa-quick.md:124-130`

**Evidence**:
```markdown
### 4. Prioritize Issues

Use this priority hierarchy:
1. **Critical** (üî¥): Security vulnerabilities from eslint-plugin-security
2. **High** (üü†): Type errors from tsc that block compilation
3. **Medium** (üü°): Quality issues from eslint (complexity, maintainability) + Unused code from knip
4. **Low** (üü¢): Style issues from eslint (formatting, naming) + React patterns
```

**Analysis**: Clear prioritization rules based on issue source (security > types > quality > style). This logic should be documented in <thinking> section to explain why issues were categorized.

### Consumer Agent Requirements Analysis

#### User/Developer (Primary Consumer)

**Role**: Reads quick QA output to fix immediate issues

**Input Requirements**:
- Fast feedback (no verbose reports)
- Clear prioritization (Critical ‚Üí High ‚Üí Medium ‚Üí Low)
- Actionable tasks with file:line references
- Tool attribution (know which tool found the issue)

**Current Satisfaction**: ‚úÖ All requirements met (task list format is concise and actionable)

**Gap Identified**: Cannot see WHAT commands were run or WHY an issue was prioritized. If user disagrees with a finding or wants to re-run a specific tool manually, no command history available.

**Example Use Case**: User sees "Type error from tsc" but wants to re-run tsc with additional flags to get more context. Without <thinking> section showing exact command, user must guess.

#### QA-Planner Agent (Secondary Consumer, Hypothetical)

**Role**: Converts quick QA task list to implementation plan (if user requests it)

**Input Requirements** (inferred):
- Structured task list with checkboxes
- File:line references for each issue
- Clear prioritization for sequencing

**Current Satisfaction**: ‚úÖ Quick QA output provides structured tasks

**Gap Identified**: QA-Planner would need to parse entire output including Scan Summary and Next Steps. If output included <thinking> section with tool execution logs, QA-Planner would waste tokens processing that reasoning. Separating <thinking>/<answer> would allow QA-Planner to strip thinking section.

**Token Savings**: Estimated 10-15% reduction in QA-Planner input tokens if thinking section can be stripped.

#### Implementation-Controller (Tertiary Consumer, Hypothetical)

**Role**: Executes fixes for quick QA findings (if user converts to implementation plan)

**Input Requirements**: None (consumes QA-Planner output, not quick QA output directly)

**Gap Identified**: None (no direct consumption)

### Comparison to python-qa-quick Agent

**Parallel Agent**: Both are "quick QA" agents for different languages

**Similarities**:
- Both use automated tools for rapid feedback (tsc/eslint/knip vs mypy/ruff/bandit)
- Both produce task lists, not detailed reports
- Both use priority hierarchy (Critical/High/Medium/Low)
- Both run tools in parallel for speed
- Both delegate to codebase-locator for file discovery
- Both use `mode: all` (can be invoked by users or other agents)

**Key Difference** (based on prior research):
- python-qa-quick is documented in AGENTS.md:37 as using thinking/answer pattern
- typescript-qa-quick is NOT documented in AGENTS.md

**Direct consequence**: Inconsistent communication pattern across parallel agents violates cross-agent consistency principle.

**Evidence**: `AGENTS.md:37`
**Excerpt**:
```markdown
- **python-qa-quick** (`agent/python-qa-quick.md`): Documents automated tool execution reasoning (commands, versions, raw outputs, synthesis decisions)
```

**Recommendation**: typescript-qa-quick should use identical <thinking> section content as python-qa-quick for consistency.

### Industry Best Practices (Background Research)

**Note**: The following findings are from prior research documented in multiple reports. They are included here for completeness but were NOT re-verified during this analysis.

#### Source 1: Anthropic Multi-Agent Research System (June 2025)

**Key Finding**: Structured thinking with `<thinking>` tags improves efficiency

**Excerpt from prior research** (2026-01-18-Codebase-Analyzer-Agent-Communication.md):
```markdown
Structured thinking with XML tags:
- Use `<thinking>` tags for reasoning
- Extended thinking mode improves instruction-following and efficiency
- Interleaved thinking after tool results
```

**Direct consequence**: Separating reasoning from findings enables debugging and token optimization.

#### Source 2: AGENTS.md Guidelines (Current)

**Thinking/Answer Pattern Benefits**:

**Evidence**: `AGENTS.md:41-47`
**Excerpt**:
```markdown
#### Benefits

- **Users see only actionable information**: ~30-70% reduction in visible text depending on agent type
- **Full reasoning trail available for debugging**: Inspect `<thinking>` section when outputs are unexpected
- **Consistent structure across agent outputs**: All primary agents use same format
- **Workflow correlation via YAML frontmatter**: `message_id` and `correlation_id` enable tracing outputs across agents
- **Token optimization**: Consumers can strip `<thinking>` section when passing results downstream (~10% savings)
```

**Applicability to typescript-qa-quick**:
- Agent produces user-facing output ‚úÖ
- Agent is all-mode (can be invoked by users or other agents) ‚úÖ
- Agent performs automated analysis requiring tool execution ‚úÖ
- Parallel agent (python-qa-quick) uses this pattern ‚úÖ

**Conclusion**: typescript-qa-quick meets ALL criteria for thinking/answer pattern adoption.

#### Source 3: Python-QA-Quick Research (2026-01-21)

**Key Finding**: Quick QA agents should document "commands, versions, raw outputs, synthesis decisions" in <thinking> section

**Evidence**: Prior research on python-qa-quick agent communication

**Applicability to typescript-qa-quick**: Identical agent role (quick automated QA), should use identical thinking section content.

## Token Impact Analysis

**Estimated Current State** (average quick QA run with ~10 findings):

**Total**: ~400-600 tokens
- Scan Summary: ~30 tokens (7%)
- Critical Issues section: ~0-100 tokens (0-25%, depends on findings)
- High Priority section: ~50-150 tokens (12-37%)
- Medium Priority section: ~50-150 tokens (12-37%)
- Low Priority section: ~20-80 tokens (5-20%)
- Next Steps: ~30-50 tokens (7%)
- No <thinking> section: 0 tokens
- No message envelope: 0 tokens

**Projected State with Recommendations**:

**Total**: ~590-850 tokens (+10-13% for typical run, +25-30% for minimal run with few findings)
- Scan Summary: ~30 tokens (4%)
- Priority sections: ~150-480 tokens (25-70%)
- Next Steps: ~30-50 tokens (5%)
- <thinking> section: ~150-200 tokens (20-30%)
- Message envelope: ~40-50 tokens (5-7%)

**Use Case Analysis**:

**User/Developer** (reading for immediate fixes):
- Current: 400-600 tokens visible
- Optimized: 400-600 tokens in <answer>, 150-200 tokens in <thinking> (inspect only if needed)
- User experience: Same actionable task list, optional debugging visibility
- Estimated visibility reduction: 0% (same content) but 100% debugging improvement (can inspect when needed)

**QA-Planner** (parsing tasks, hypothetical):
- Current: Reads entire 400-600 token output
- Optimized: Strips <thinking> section, reads only <answer> (400-600 tokens)
- Token savings: ~10-15% if thinking section can be programmatically stripped
- Net impact: +10-13% overhead in quick QA output, -10-15% savings in QA-Planner input

**Overall Multi-Agent Workflow Impact**:

Using Anthropic's guidance that multi-agent systems magnify efficiency gains:
- User debugging capability: +100% (from 0% to full reasoning visibility)
- QA-Planner token efficiency: -10-15% (if thinking stripped)
- Quick QA generation cost: +10-13% (one-time overhead)
- Consistency with python-qa-quick: Achieved (cross-agent uniformity)
- Net workflow efficiency: Positive (one-time 10-13% cost enables recurring 10-15% savings)

**Edge Case**: Minimal quick QA run with 0-2 findings
- Current: ~200-300 tokens (mostly empty sections)
- Optimized: ~390-500 tokens (+25-30% overhead)
- Analysis: Higher percentage overhead for minimal runs, but absolute token count remains low (<500 tokens)

## Verification Log

**Verified** (files personally read):
- `agent/typescript-qa-quick.md:1-318` (verified complete at 318 lines)
- `AGENTS.md:1-100` (spot-checked for thinking/answer pattern, verified python-qa-quick entry at line 37)

**Spot-checked excerpts captured**: Yes

**Background Research** (relied on prior analysis, not re-verified):
- `thoughts/shared/research/2026-01-20-OpenCode-QA-Thorough-Agent-Communication.md` (QA agent patterns)
- `thoughts/shared/research/2026-01-21-Python-QA-Quick-Agent-Communication.md` (parallel agent analysis)
- `thoughts/shared/research/2026-01-18-Codebase-Analyzer-Agent-Communication.md` (industry best practices from 7 authoritative sources)

**Assumptions**:
- QA-Planner agent may consume quick QA outputs in future (inferred from workflow patterns, not verified)
- typescript-qa-quick should mirror python-qa-quick communication pattern (based on parallel agent principle)

## Open Questions / Unverified Claims

### Question 1: QA-Planner Consumption of Quick QA Output

**Claim**: QA-Planner may consume typescript-qa-quick output to create implementation plans.

**What I tried**:
- Reviewed AGENTS.md for QA workflow documentation
- Found references to QA workflow but no explicit mention of quick QA ‚Üí QA-Planner flow

**Evidence missing**: QA-Planner agent definition and confirmed workflow integration

**Implication**: Token optimization benefits for downstream consumers may not be realized if QA-Planner doesn't consume quick QA outputs. However, user debugging benefits remain valid.

### Question 2: Actual Quick QA Token Counts

**Claim**: Estimated 400-600 tokens for typical quick QA run with ~10 findings.

**What I tried**:
- Analyzed template structure
- Estimated tokens per section using ~2-3 tokens per word heuristic

**Evidence missing**: Actual token count measured by LLM tokenizer on real quick QA run

**Implication**: Token impact projections are estimates, not measured data. Actual overhead could be higher or lower.

### Question 3: Thinking Section Content Specification

**Claim**: <thinking> section should include commands, versions, raw outputs, synthesis decisions (matching python-qa-quick).

**What I tried**:
- Reviewed python-qa-quick thinking section specification from prior research
- Identified information types needed for debugging typescript-qa-quick

**Evidence missing**: User feedback on what reasoning details are most valuable for TypeScript QA debugging

**Implication**: <thinking> section design is based on researcher judgment and parallel agent consistency, not validated user requirements. May include too much or too little detail.

### Question 4: Message Envelope Schema Standardization

**Claim**: Message envelope should include message_id, correlation_id, timestamp, message_type, qa_agent_version, target_path, summary metrics.

**What I tried**:
- Reviewed AGENTS.md thinking/answer pattern
- Checked python-qa-quick research for message envelope standards

**Evidence missing**: Standardized schema definition for quick QA message envelope across all QA agents (python-qa-quick, typescript-qa-quick, etc.)

**Implication**: Each quick QA agent may implement different envelope fields, reducing consistency benefits. Should align with python-qa-quick envelope schema.

## Recommendations (Evidence-Based)

### Recommendation 1: Add Thinking/Answer Separation (CRITICAL)

**Change**: Wrap typescript-qa-quick output in `<thinking>` and `<answer>` tags

**Before** (current):
```markdown
## Output Format

Use this exact Markdown structure:

```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD
```
```

**After** (recommended):
```markdown
## Output Format

Produce output with thinking/answer separation:

<thinking>
Tool Execution Log:

Phase 1 - Target Discovery:
- User provided: [path] OR delegated to codebase-locator
- Found TypeScript files: [count] files

Phase 2 - Tool Execution (Parallel):
- tsc command: npx tsc --noEmit
- tsc version: [version detected]
- tsc raw output: [first 10 lines or "PASSED"]
- eslint command: npx eslint . --ext .ts,.tsx
- eslint version: [version detected]
- eslint raw output: [first 10 lines or "PASSED"]
- knip command: npx knip --reporter compact
- knip version: [version detected]
- knip raw output: [first 10 lines or "PASSED"]

Phase 3 - Optional Tool Detection:
- eslint-plugin-security: [detected/not found]
- eslint-plugin-jsdoc: [detected/not found]
- Optional tools executed: [commands if any]

Phase 4 - Issue Synthesis:
- Total issues found: [count]
- Critical issues: [count] (from eslint-plugin-security)
- High priority issues: [count] (from tsc)
- Medium priority issues: [count] (from eslint + knip)
- Low priority issues: [count] (from eslint style rules)
- Grouping applied: [yes/no, reason]

Phase 5 - Prioritization Decisions:
- Critical: Security vulnerabilities flagged by eslint-plugin-security (rule: security > all)
- High: Type errors blocking compilation (rule: types > quality)
- Medium: Quality/maintainability issues (rule: quality > style)
- Low: Style/formatting issues (rule: style = lowest priority)
</thinking>

<answer>
```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD

[rest of template unchanged]
```
</answer>
```

**Justification**:
- Matches AGENTS.md guideline for agents that produce user-facing output (AGENTS.md:9-27)
- Enables users to inspect tool commands and raw outputs for debugging
- Allows hypothetical QA-Planner to strip <thinking> for token optimization (~10-15% savings)
- Provides audit trail (exact commands, versions, issue counts)
- Achieves consistency with parallel python-qa-quick agent (AGENTS.md:37)
- Industry best practice (Anthropic official recommendation)

**Implementation**:
- Update `agent/typescript-qa-quick.md:136` to add <thinking>/<answer> wrapper instruction
- Add explicit list of information to log in <thinking> section (5 phases: target discovery, tool execution, optional tool detection, issue synthesis, prioritization decisions)
- Match python-qa-quick thinking section content for consistency
- Update AGENTS.md:29-39 to add typescript-qa-quick to thinking/answer pattern list

**Token Impact**: +150-200 tokens (+10-13%) per quick QA run, enables ~10-15% savings for QA-Planner

**Priority**: **HIGH** - Aligns with documented agent communication patterns, achieves cross-agent consistency with python-qa-quick

### Recommendation 2: Add Structured Message Envelope

**Change**: Add YAML frontmatter to quick QA output

**Before** (current):
```markdown
```markdown
## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì
- Date: YYYY-MM-DD
```
```

**After** (recommended):
```markdown
<answer>
---
message_id: ts-qa-quick-2026-01-21-001
correlation_id: qa-workflow-auth-module
timestamp: 2026-01-21T14:30:00Z
message_type: QUICK_QA_TYPESCRIPT
qa_agent: typescript-qa-quick
qa_agent_version: "1.0"
target_path: src/auth/
target_type: directory
tools_executed: ["tsc", "eslint", "knip", "eslint-plugin-security"]
overall_status: Issues Found
critical_issues: 2
high_priority_issues: 5
medium_priority_issues: 8
low_priority_issues: 3
---

## üöÄ Quick TypeScript QA Results

### ‚è±Ô∏è Scan Summary
- Target: [path]
- Tools: tsc ‚úì | eslint ‚úì | knip ‚úì | eslint-plugin-security ‚úì
- Date: YYYY-MM-DD

[rest of template unchanged]
```
</answer>
```

**Justification**:
- Industry standard for multi-agent message passing (ApXML Communication Protocols, prior research)
- Enables workflow correlation: quick QA ‚Üí user fixes ‚Üí re-run QA
- Supports programmatic parsing and debugging tools
- Consistent with python-qa-quick message envelope (should use identical schema)
- Minimal overhead (~3%) for significant tooling value

**Implementation**:
- Update `agent/typescript-qa-quick.md:136` to add YAML frontmatter before template
- Auto-generate message_id using timestamp + sequence
- Accept correlation_id from caller (or generate from target path)
- Include summary metrics in frontmatter for quick parsing
- Align schema with python-qa-quick for cross-language consistency

**Token Impact**: +40-50 tokens (+3%) per quick QA run

**Priority**: **MEDIUM** - Workflow correlation is valuable but not blocking current functionality

### Recommendation 3: Document in AGENTS.md Thinking/Answer Pattern List

**Change**: Add typescript-qa-quick to AGENTS.md thinking/answer pattern list

**Before** (current):
```markdown
#### Agents Using This Pattern

- **task-executor** (`agent/task-executor.md`): Documents task execution reasoning
- **implementation-controller** (`agent/implementation-controller.md`): Documents orchestration reasoning
- **codebase-analyzer** (`agent/codebase-analyzer.md`): Documents code analysis reasoning
- **codebase-locator** (`agent/codebase-locator.md`): Documents file discovery reasoning
- **codebase-pattern-finder** (`agent/codebase-pattern-finder.md`): Documents pattern search reasoning
- **opencode-qa-thorough** (`agent/opencode-qa-thorough.md`): Documents QA analysis reasoning
- **python-qa-quick** (`agent/python-qa-quick.md`): Documents automated tool execution reasoning (commands, versions, raw outputs, synthesis decisions)
- **python-qa-thorough** (`agent/python-qa-thorough.md`): Documents comprehensive Python QA reasoning
- **web-search-researcher** (`agent/web-search-researcher.md`): Documents external research reasoning
```

**After** (recommended):
```markdown
#### Agents Using This Pattern

- **task-executor** (`agent/task-executor.md`): Documents task execution reasoning
- **implementation-controller** (`agent/implementation-controller.md`): Documents orchestration reasoning
- **codebase-analyzer** (`agent/codebase-analyzer.md`): Documents code analysis reasoning
- **codebase-locator** (`agent/codebase-locator.md`): Documents file discovery reasoning
- **codebase-pattern-finder** (`agent/codebase-pattern-finder.md`): Documents pattern search reasoning
- **opencode-qa-thorough** (`agent/opencode-qa-thorough.md`): Documents QA analysis reasoning
- **python-qa-quick** (`agent/python-qa-quick.md`): Documents automated tool execution reasoning (commands, versions, raw outputs, synthesis decisions)
- **python-qa-thorough** (`agent/python-qa-thorough.md`): Documents comprehensive Python QA reasoning
- **typescript-qa-quick** (`agent/typescript-qa-quick.md`): Documents automated tool execution reasoning (commands, versions, raw outputs, synthesis decisions)
- **web-search-researcher** (`agent/web-search-researcher.md`): Documents external research reasoning
```

**Justification**:
- Ensures documentation consistency
- Makes thinking/answer pattern discoverable for typescript-qa-quick users
- Highlights parallel structure with python-qa-quick (identical thinking section description)

**Implementation**:
- Update `AGENTS.md:29-39` to add typescript-qa-quick entry
- Use identical description as python-qa-quick entry for consistency

**Token Impact**: No change to agent output; documentation update only

**Priority**: **LOW** - Documentation improvement, not functional change

### Recommendation 4: Add Thinking Section Content Specification

**Change**: Add explicit guidance in agent prompt for what to log in <thinking> section

**Addition to `agent/typescript-qa-quick.md`** (after section 2, before section 3):

```markdown
### 2.5 Document Tool Execution Process (For <thinking> Section)

Log the following information for user debugging and transparency:

1. **Target Discovery**:
   - How target was identified (user-provided path vs codebase-locator delegation)
   - TypeScript files discovered (count)

2. **Tool Execution** (for each tool):
   - Exact command executed (e.g., `npx tsc --noEmit`)
   - Tool version detected (from --version output)
   - Raw output summary (first 10 lines if errors, "PASSED" if clean)

3. **Optional Tool Detection**:
   - Which optional tools were detected in package.json or eslint config
   - Which optional tools were executed (commands)

4. **Issue Synthesis**:
   - Total issues found (before grouping)
   - Issue count by priority (Critical/High/Medium/Low)
   - Grouping applied (yes/no, reason if >20 issues in any category)

5. **Prioritization Decisions**:
   - Why each priority level was assigned (rule: security > types > quality > style)
   - Which tool outputs mapped to which priority levels
```

**Justification**:
- Prevents under-specified or over-specified <thinking> sections
- Ensures consistent thinking content across TypeScript QA runs
- Matches python-qa-quick thinking section specification (identical 5-phase structure)
- Helps users understand exactly what information will be available for debugging

**Implementation**:
- Insert new section at `agent/typescript-qa-quick.md:95` (after section 2, before section 3)
- Reference this section in output format instruction: "Wrap tool execution log from section 2.5 in <thinking> tags"

**Token Impact**: +80-120 tokens in agent prompt (one-time), ensures consistent 150-200 token thinking sections in output

**Priority**: **MEDIUM** - Improves thinking section quality and consistency

### Recommendation 5: Align Message Envelope Schema with python-qa-quick

**Change**: Ensure YAML frontmatter schema matches python-qa-quick for cross-language consistency

**Schema Fields** (should match python-qa-quick):
```yaml
message_id: [qa-type]-[date]-[sequence]
correlation_id: [workflow-context]
timestamp: [ISO 8601]
message_type: QUICK_QA_[LANGUAGE]
qa_agent: [agent-name]
qa_agent_version: [version]
target_path: [path]
target_type: [file|directory|module]
tools_executed: [array]
overall_status: [Pass|Issues Found|Blocked]
critical_issues: [count]
high_priority_issues: [count]
medium_priority_issues: [count]
low_priority_issues: [count]
```

**Justification**:
- Polyglot projects will use both python-qa-quick and typescript-qa-quick
- Identical schema enables unified tooling (dashboard, CI/CD integration)
- Reduces cognitive load for users working across languages

**Implementation**:
- Cross-reference python-qa-quick agent definition to extract exact frontmatter schema
- Use identical field names and value formats in typescript-qa-quick
- Document shared schema in AGENTS.md or separate reference doc

**Token Impact**: 0 tokens (schema alignment, not additional fields)

**Priority**: **LOW** - Consistency improvement for polyglot projects

## Implementation Roadmap (Suggested Sequence)

### Phase 1: High-Impact Core Changes
1. **Recommendation 4**: Add thinking section content specification (define what to log)
2. **Recommendation 1**: Add thinking/answer separation (update template with <thinking>/<answer> tags)
3. **Test**: Run typescript-qa-quick on sample TypeScript project, verify thinking section includes expected content

**Estimated effort**: 2-4 hours
**Token impact**: +10-13% per quick QA run

### Phase 2: Cross-Agent Consistency
4. **Recommendation 5**: Align message envelope schema with python-qa-quick
5. **Recommendation 2**: Add message envelope (YAML frontmatter)
6. **Test**: Compare typescript-qa-quick output to python-qa-quick output, verify identical structure

**Estimated effort**: 2-3 hours
**Token impact**: +3% for message envelope

### Phase 3: Documentation & Discoverability
7. **Recommendation 3**: Document in AGENTS.md thinking/answer pattern list
8. **Documentation**: Update AGENTS.md QA workflow section with typescript-qa-quick details
9. **Migration guide**: Document changes for users accustomed to old quick QA format

**Estimated effort**: 1-2 hours
**Token impact**: 0% (documentation only)

**Total estimated effort**: 5-9 hours
**Total token impact**:
- Quick QA generation: +10-13% (one-time overhead per run)
- QA-Planner consumption: -10-15% (recurring savings, hypothetical)
- User debugging capability: +100% (from none to full reasoning visibility)
- Cross-agent consistency: Achieved (typescript-qa-quick matches python-qa-quick)

## Acceptance Criteria

For implementation to be considered complete:

1. **Thinking/Answer Separation**: Quick QA output wrapped in `<thinking>` and `<answer>` tags
2. **Thinking Content**: <thinking> section includes all 5 phases (target discovery, tool execution with commands/versions/outputs, optional tool detection, issue synthesis, prioritization decisions)
3. **Message Envelope**: YAML frontmatter includes all standard fields (message_id, correlation_id, timestamp, message_type, qa_agent, target_path, summary metrics)
4. **Schema Alignment**: YAML frontmatter schema matches python-qa-quick (identical field names and value formats)
5. **Template Consistency**: <answer> section uses existing task list format (no changes to findings presentation)
6. **Documentation**: AGENTS.md thinking/answer pattern list includes typescript-qa-quick entry with identical description as python-qa-quick
7. **Verification**: Sample quick QA run produces output with both sections, thinking section includes all 5 phases
8. **Cross-Agent Consistency**: Side-by-side comparison of typescript-qa-quick and python-qa-quick outputs shows identical structure (only tool names and language-specific content differ)

## References

**Files Verified**:
- `agent/typescript-qa-quick.md:1-318` (agent definition and template, verified complete)
- `AGENTS.md:1-100` (spot-checked for thinking/answer pattern, verified python-qa-quick entry)

**Background Research** (relied on prior analysis):
- `thoughts/shared/research/2026-01-20-OpenCode-QA-Thorough-Agent-Communication.md` (QA agent communication patterns)
- `thoughts/shared/research/2026-01-21-Python-QA-Quick-Agent-Communication.md` (parallel agent analysis)
- `thoughts/shared/research/2026-01-18-Codebase-Analyzer-Agent-Communication.md` (industry best practices, 7 authoritative sources)
